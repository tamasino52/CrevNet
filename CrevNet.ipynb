{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import time\n",
    "from skimage.measure import compare_ssim\n",
    "from tqdm import trange\n",
    "import easydict\n",
    "\n",
    "# Local Module\n",
    "import pssim.pytorch_ssim as pytorch_ssim\n",
    "import utils.data_utils as data_utils\n",
    "import utils.utils as utils\n",
    "import utils.utils_3d as utils_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = easydict.EasyDict({})\n",
    "opt.lr = 0.0005\n",
    "opt.beta1 = 0.9\n",
    "opt.batch_size = 7\n",
    "opt.log_dir = 'logs'\n",
    "opt.model_dir = ''\n",
    "opt.name = ''\n",
    "opt.data_root = 'data'\n",
    "opt.optimizer = optim.Adam\n",
    "opt.data_type = 'sequence'\n",
    "opt.niter = 60\n",
    "opt.epoch_size =5000\n",
    "opt.image_width = 64\n",
    "opt.channels = 1\n",
    "opt.dataset = 'smmnist'\n",
    "opt.n_past = 8\n",
    "opt.n_future = 10\n",
    "opt.n_eval = 18\n",
    "opt.rnn_size = 32\n",
    "opt.predictor_rnn_layers = 8\n",
    "opt.beta = 0.0001\n",
    "opt.model = 'crevnet'\n",
    "opt.data_threads = 0\n",
    "opt.num_digits = 2\n",
    "opt.max_step = opt.n_past + opt.n_future + 2\n",
    "\n",
    "# Random seed setting\n",
    "opt.seed = 1\n",
    "random.seed(opt.seed)\n",
    "torch.manual_seed(opt.seed)\n",
    "torch.cuda.manual_seed_all(opt.seed)\n",
    "dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folder naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.model_dir != '':\n",
    "    saved_model = torch.load('%s/model.pth' % opt.model_dir)\n",
    "    optimizer = opt.optimizer\n",
    "    model_dir = opt.model_dir\n",
    "    opt = saved_model['opt']\n",
    "    opt.optimizer = optimizer\n",
    "    opt.model_dir = model_dir\n",
    "    opt.log_dir = '%s/continued' % opt.log_dir\n",
    "else:\n",
    "    name = 'model_mnist=layers_%s=seq_len_%s=batch_size_%s' % (opt.predictor_rnn_layers,opt.n_eval,opt.batch_size)\n",
    "    if opt.dataset == 'smmnist':\n",
    "        opt.log_dir = '%s/%s-%d/%s' % (opt.log_dir, opt.dataset, opt.num_digits, name)\n",
    "    else:\n",
    "        opt.log_dir = '%s/%s/%s' % (opt.log_dir, opt.dataset, name)\n",
    "\n",
    "os.makedirs('%s/gen/' % opt.log_dir, exist_ok=True)\n",
    "os.makedirs('%s/plots/' % opt.log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AutoEncoder.AutoEncoder import AutoEncoder\n",
    "from RPM.ReversiblePredictor import ReversiblePredictor\n",
    "\n",
    "frame_predictor = ReversiblePredictor(input_size=opt.rnn_size,\n",
    "                                      hidden_size=opt.rnn_size, \n",
    "                                      output_size=opt.rnn_size, \n",
    "                                      n_layers=opt.predictor_rnn_layers, \n",
    "                                      batch_size=opt.batch_size)\n",
    "\n",
    "encoder = AutoEncoder(nBlocks=[4,5,3], \n",
    "                      nStrides=[1, 2, 2],\n",
    "                      nChannels=None,\n",
    "                      init_ds=2,\n",
    "                      dropout_rate=0., \n",
    "                      affineBN=True, \n",
    "                      in_shape=[opt.channels, opt.image_width, opt.image_width],\n",
    "                      mult=2)\n",
    "\n",
    "frame_predictor_optimizer = opt.optimizer(frame_predictor.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "encoder_optimizer = opt.optimizer(encoder.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "\n",
    "scheduler1 = torch.optim.lr_scheduler.StepLR(frame_predictor_optimizer, step_size=50, gamma=0.2)\n",
    "scheduler2 = torch.optim.lr_scheduler.StepLR(encoder_optimizer, step_size=50, gamma=0.2)\n",
    "\n",
    "mse_criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame_predictor.cuda()\n",
    "encoder.cuda()\n",
    "mse_criterion.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thdsn\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:208: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = data_utils.load_dataset(opt)\n",
    "\n",
    "train_loader = DataLoader(train_data,\n",
    "                          num_workers=opt.data_threads,\n",
    "                          batch_size=opt.batch_size,\n",
    "                          shuffle=True,\n",
    "                          drop_last=True,\n",
    "                          pin_memory=False)\n",
    "test_loader = DataLoader(test_data,\n",
    "                         num_workers=opt.data_threads,\n",
    "                         batch_size=opt.batch_size,\n",
    "                         shuffle=True,\n",
    "                         drop_last=True,\n",
    "                         pin_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_batch():\n",
    "    while True:\n",
    "        for sequence in train_loader:\n",
    "            batch = data_utils.normalize_data(opt, dtype, sequence)\n",
    "            yield batch\n",
    "            \n",
    "def get_testing_batch():\n",
    "    while True:\n",
    "        for sequence in test_loader:\n",
    "            batch = data_utils.normalize_data(opt, dtype, sequence)\n",
    "            yield batch\n",
    "            \n",
    "training_batch_generator = get_training_batch()\n",
    "testing_batch_generator = get_testing_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(x, epoch,p = False):\n",
    "    nsample = 1\n",
    "    gen_seq = [[] for i in range(nsample)]\n",
    "    gt_seq = [x[i] for i in range(len(x))]\n",
    "    mse = 0\n",
    "    for s in range(nsample):\n",
    "        frame_predictor.hidden = frame_predictor.init_hidden()\n",
    "        memo = Variable(torch.zeros(opt.batch_size, opt.rnn_size, 3, int(opt.image_width/8), int(opt.image_width/8)).cuda())\n",
    "        gen_seq[s].append(x[0])\n",
    "        x_in = x[0]\n",
    "        for i in range(1, opt.n_eval):\n",
    "            h = encoder(x_in)\n",
    "            if i < opt.n_past:\n",
    "                _,memo = frame_predictor((h,memo))\n",
    "                x_in = x[i]\n",
    "                gen_seq[s].append(x_in)\n",
    "            elif i == opt.n_past:\n",
    "                h_pred, memo = frame_predictor((h, memo))\n",
    "                x_in = encoder(h_pred, False).detach()\n",
    "                x_in[:, :, 0] = x[i][:, :, 0]\n",
    "                x_in[:, :, 1] = x[i][:, :, 1]\n",
    "                gen_seq[s].append(x_in)\n",
    "            elif i == opt.n_past + 1:\n",
    "                h_pred, memo = frame_predictor((h, memo))\n",
    "                x_in = encoder(h_pred, False).detach()\n",
    "                x_in[:, :, 0] = x[i][:, :, 0]\n",
    "                gen_seq[s].append(x_in)\n",
    "            else:\n",
    "                h_pred, memo = frame_predictor((h, memo))\n",
    "                x_in =encoder(h_pred,False).detach()\n",
    "                gen_seq[s].append(x_in)\n",
    "\n",
    "    to_plot = []\n",
    "    gifs = [[] for t in range(opt.n_eval)]\n",
    "    nrow = min(opt.batch_size, 10)\n",
    "    for i in range(nrow):\n",
    "        # ground truth sequence\n",
    "        row = []\n",
    "        for t in range(opt.n_eval):\n",
    "            row.append(gt_seq[t][i][0][2])\n",
    "        to_plot.append(row)\n",
    "        mse = 0\n",
    "        for s in range(nsample):\n",
    "            for t in range(opt.n_past,opt.n_eval):\n",
    "                mse += pytorch_ssim.ssim(gt_seq[t][:,0,2][:,None, :, :],gen_seq[s][t][:,0,2][:,None, :, :])\n",
    "        s_list = [0]\n",
    "        for ss in range(len(s_list)):\n",
    "            s = s_list[ss]\n",
    "            row = []\n",
    "            for t in range(opt.n_eval):\n",
    "                row.append(gen_seq[s][t][i][0][2])\n",
    "            to_plot.append(row)\n",
    "        for t in range(opt.n_eval):\n",
    "            row = []\n",
    "            row.append(gt_seq[t][i][0][2])\n",
    "            for ss in range(len(s_list)):\n",
    "                s = s_list[ss]\n",
    "                row.append(gen_seq[s][t][i][0][2])\n",
    "            gifs[t].append(row)\n",
    "\n",
    "    if p:\n",
    "        fname = '%s/gen/sample_%d.png' % (opt.log_dir, epoch)\n",
    "        data_utils.save_tensors_image(fname, to_plot)\n",
    "\n",
    "        fname = '%s/gen/sample_%d.gif' % (opt.log_dir, epoch)\n",
    "        data_utils.save_gif(fname, gifs)\n",
    "    return mse / 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, e):\n",
    "    frame_predictor.zero_grad()\n",
    "    encoder.zero_grad()\n",
    "\n",
    "    # initialize the hidden state.\n",
    "    frame_predictor.hidden = frame_predictor.init_hidden()\n",
    "    mse = 0\n",
    "\n",
    "    memo = Variable(torch.zeros(opt.batch_size, opt.rnn_size, 3, int(opt.image_width/8), int(opt.image_width/8)).cuda())\n",
    "    for i in range(1, opt.n_past + opt.n_future):\n",
    "        h = encoder(x[i - 1], True)\n",
    "        h_pred, memo = frame_predictor((h, memo))\n",
    "        x_pred = encoder(h_pred,False)\n",
    "        mse += (mse_criterion(x_pred, x[i]))\n",
    "\n",
    "    loss = mse\n",
    "    loss.backward()\n",
    "\n",
    "    frame_predictor_optimizer.step()\n",
    "    encoder_optimizer.step()\n",
    "\n",
    "    return mse.data.cpu().numpy() / (opt.n_past + opt.n_future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/5000 [00:00<?, ?it/s]C:\\Users\\thdsn\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "C:\\Users\\thdsn\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      " 61%|████████████████████████████████████████████▉                             | 3036/5000 [2:05:42<1:34:56,  2.90s/it]"
     ]
    }
   ],
   "source": [
    "for epoch in range(opt.niter):\n",
    "    frame_predictor.train()\n",
    "    encoder.train()\n",
    "    epoch_mse = 0\n",
    "\n",
    "    for i in trange(opt.epoch_size):\n",
    "        x = next(training_batch_generator)\n",
    "        input = []\n",
    "        for j in range(opt.n_eval):\n",
    "            k1 = x[j][:, 0][:,None,None,:,:]\n",
    "            k2 = x[j + 1][:, 0][:,None,None,:,:]\n",
    "            k3 = x[j + 2][:, 0][:,None,None,:,:]\n",
    "\n",
    "            input.append(torch.cat((k1,k2,k3),2))\n",
    "        mse = 0\n",
    "        mse = train(input,epoch)\n",
    "        epoch_mse += mse\n",
    "\n",
    "    scheduler1.step()\n",
    "    scheduler2.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        frame_predictor.eval()\n",
    "        encoder.eval()\n",
    "\n",
    "        eval = 0\n",
    "        for i in range(100):\n",
    "            x = next(testing_batch_generator)\n",
    "            input = []\n",
    "            for j in range(opt.n_eval):\n",
    "                k1 = x[j][:, 0][:, None, None, :, :]\n",
    "                k2 = x[j + 1][:, 0][:, None, None, :, :]\n",
    "                k3 = x[j + 2][:, 0][:, None, None, :, :]\n",
    "\n",
    "                input.append(torch.cat((k1, k2, k3), 2))\n",
    "            if i == 0:\n",
    "                ssim = plot(input, epoch, True)\n",
    "            else:\n",
    "                ssim = plot(input, epoch)\n",
    "            eval += ssim\n",
    "\n",
    "        print('[%02d] mse loss: %.7f| ssim loss: %.7f(%d)' % (\n",
    "            epoch, epoch_mse / opt.epoch_size,eval/ 100.0, epoch * opt.epoch_size * opt.batch_size))\n",
    "\n",
    "    # save the model\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save({\n",
    "            'encoder': encoder,\n",
    "            'frame_predictor': frame_predictor,\n",
    "            'opt': opt},\n",
    "            '%s/model_%s.pth' % (opt.log_dir,epoch))\n",
    "\n",
    "    torch.save({\n",
    "        'encoder': encoder,\n",
    "        'frame_predictor': frame_predictor,\n",
    "        'opt': opt},\n",
    "        '%s/model.pth' % opt.log_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
